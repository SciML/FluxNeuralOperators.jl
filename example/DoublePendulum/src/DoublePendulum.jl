module DoublePendulum

using NeuralOperators
using Flux
using CUDA

include("data.jl")

__init__() = register_double_pendulum_chaotic()

function train()
    if has_cuda()
        @info "CUDA is on"
        device = gpu
        CUDA.allowscalar(false)
    else
        device = cpu
    end

    m = Chain(
        FourierOperator(6=>6, (16, ), gelu),
        FourierOperator(6=>6, (16, ), gelu),
        FourierOperator(6=>6, (16, ), gelu),
        FourierOperator(6=>6, (16, )),
    ) |> device

    loss(ð±, ð²) = sum(abs2, ð² .- m(ð±)) / size(ð±)[end]

    loader_train, loader_test = get_dataloader()

    function validate()
        validation_losses = [loss(device(ð±), device(ð²)) for (ð±, ð²) in loader_test]
        @info "loss: $(sum(validation_losses)/length(loader_test))"
    end

    data = [(ð±, ð²) for (ð±, ð²) in loader_train] |> device
    opt = Flux.Optimiser(WeightDecay(1f-4), Flux.ADAM(1f-4))
    call_back = Flux.throttle(validate, 0.5, leading=false, trailing=true)
    Flux.@epochs 500 @time(Flux.train!(loss, params(m), data, opt, cb=call_back))
end

end
