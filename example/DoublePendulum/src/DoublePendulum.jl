module DoublePendulum

using DataDeps, CSV, DataFrames, MLUtils
using NeuralOperators, Flux
using CUDA, FluxTraining, BSON

function register_double_pendulum_chaotic()
    register(DataDep(
        "DoublePendulumChaotic",
        """
        Dataset was generated on the basis of 21 individual runs of a double pendulum.
        Each of the recorded sequences lasted around 40s and consisted of around 17500 frames.

        * `x_red`: Horizontal pixel coordinate of the red point (the central pivot to the first pendulum)
        * `y_red`: Vertical pixel coordinate of the red point (the central pivot to the first pendulum)
        * `x_green`: Horizontal pixel coordinate of the green point (the first pendulum)
        * `y_green`: Vertical pixel coordinate of the green point (the first pendulum)
        * `x_blue`: Horizontal pixel coordinate of the blue point (the second pendulum)
        * `y_blue`: Vertical pixel coordinate of the blue point (the second pendulum)

        Page: https://developer.ibm.com/exchanges/data/all/double-pendulum-chaotic/
        """,
        "https://dax-cdn.cdn.appdomain.cloud/dax-double-pendulum-chaotic/2.0.1/double-pendulum-chaotic.tar.gz",
        "4ca743b4b783094693d313ebedc2e8e53cf29821ee8b20abd99f8fb4c0866f8d",
        post_fetch_method=unpack
    ))
end

function get_data(; i=0, n=-1)
    data_path = joinpath(datadep"DoublePendulumChaotic", "original", "dpc_dataset_csv")
    df = CSV.read(
        joinpath(data_path, "$i.csv"),
        DataFrame,
        header=[:x_red, :y_red, :x_green, :y_green, :x_blue, :y_blue]
    )
    data = (n < 0) ? collect(Matrix(df)') : collect(Matrix(df)')[:, 1:n]

    return Float32.(data)
end

function preprocess(ð±; Î”t=1, nx=30, ny=30)
    # move red point to (0, 0)
    xs_red, ys_red = ð±[1, :], ð±[2, :]
    ð±[3, :] -= xs_red; ð±[5, :] -= xs_red
    ð±[4, :] -= ys_red; ð±[6, :] -= ys_red

    # needs only green and blue points
    ð± = reshape(ð±[3:6, 1:Î”t:end], 1, 4, :)
    # velocity of green and blue points
    âˆ‡ð± = ð±[:, :, 2:end] - ð±[:, :, 1:(end-1)]
    # merge info of pos and velocity
    ð± = cat(ð±[:, :, 1:(end-1)], âˆ‡ð±, dims=1)

    # with info of first nx steps to inference next ny steps
    n = size(ð±)[end] - (nx + ny) + 1
    ð±s = Array{Float32}(undef, size(ð±)[1:2]..., nx, n)
    ð²s = Array{Float32}(undef, size(ð±)[1:2]..., ny, n)
    for i in 1:n
        ð±s[:, :, :, i] .= ð±[:, :, i:(i+nx-1)]
        ð²s[:, :, :, i] .= ð±[:, :, (i+nx):(i+nx+ny-1)]
    end

    return ð±s, ð²s
end

function get_dataloader(; n_file=20, Î”t=1, nx=30, ny=30, ratio=0.9, batchsize=100)
    ð±s, ð²s = Array{Float32}(undef, 2, 4, nx, 0), Array{Float32}(undef, 2, 4, ny, 0)
    for i in 0:(n_file-1)
        ð±s_i, ð²s_i = preprocess(get_data(i=i), Î”t=Î”t, nx=nx, ny=ny)
        ð±s, ð²s = cat(ð±s, ð±s_i, dims=4), cat(ð²s, ð²s_i, dims=4)
    end

    data = shuffleobs((ð±s, ð²s))
    data_train, data_test = splitobs(data, at=ratio)

    loader_train = Flux.DataLoader(data_train, batchsize=batchsize, shuffle=true)
    loader_test = Flux.DataLoader(data_test, batchsize=batchsize, shuffle=false)

    return loader_train, loader_test
end

__init__() = register_double_pendulum_chaotic()

function train(; cuda=true, Î”t=1, Î·â‚€=1f-3, Î»=1f-4, epochs=20)
    if cuda && CUDA.has_cuda()
        device = gpu
        CUDA.allowscalar(false)
        @info "Training on GPU"
    else
        device = cpu
        @info "Training on CPU"
    end

    model = FourierNeuralOperator(ch=(2, 64, 64, 64, 64, 64, 128, 2), modes=(4, 16), Ïƒ=gelu)
    data = get_dataloader(Î”t=Î”t)
    optimiser = Flux.Optimiser(WeightDecay(Î»), Flux.ADAM(Î·â‚€))
    loss_func = lâ‚‚loss

    learner = Learner(
        model, data, optimiser, loss_func,
        ToDevice(device, device),
        Checkpointer(joinpath(@__DIR__, "../model/"))
    )

    fit!(learner, epochs)

    return learner
end

function get_model()
    model_path = joinpath(@__DIR__, "../model/")
    model_file = readdir(model_path)[end]

    return BSON.load(joinpath(model_path, model_file), @__MODULE__)[:model]
end

end # module
