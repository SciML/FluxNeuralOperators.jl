<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>APIs ¬∑ NeuralOperators.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link rel="canonical" href="https://docs.sciml.ai/NeuralOperators/stable/apis/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="NeuralOperators.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">NeuralOperators.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../introduction/">Introduction</a></li><li class="is-active"><a class="tocitem" href>APIs</a><ul class="internal"><li><a class="tocitem" href="#Transforms"><span>Transforms</span></a></li><li><a class="tocitem" href="#Layers"><span>Layers</span></a></li><li><a class="tocitem" href="#Models"><span>Models</span></a></li></ul></li><li><a class="tocitem" href="../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>APIs</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>APIs</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/SciML/NeuralOperators.jl/blob/main/docs/src/apis.md#" title="Edit on GitHub"><span class="docs-icon fab">ÔÇõ</span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="APIs"><a class="docs-heading-anchor" href="#APIs">APIs</a><a id="APIs-1"></a><a class="docs-heading-anchor-permalink" href="#APIs" title="Permalink"></a></h1><h2 id="Transforms"><a class="docs-heading-anchor" href="#Transforms">Transforms</a><a id="Transforms-1"></a><a class="docs-heading-anchor-permalink" href="#Transforms" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="NeuralOperators.AbstractTransform" href="#NeuralOperators.AbstractTransform"><code>NeuralOperators.AbstractTransform</code></a> ‚Äî <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AbstractTransform</code></pre><p><strong>Interface</strong></p><ul><li><code>Base.ndims(&lt;:AbstractTransform)</code>: N dims of modes</li><li><code>transform(&lt;:AbstractTransform, ùê±::AbstractArray)</code>: Apply the transform to ùê±</li><li><code>truncate_modes(&lt;:AbstractTransform, ùê±_transformed::AbstractArray)</code>: Truncate modes that contribute to the noise</li><li><code>inverse(&lt;:AbstractTransform, ùê±_transformed::AbstractArray)</code>: Apply the inverse transform to ùê±_transformed</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralOperators.jl/blob/3b8e3c5cac08fad771940e82f8ae55247a85785f/src/Transform/Transform.jl#L7-L16">source</a></section></article><h2 id="Layers"><a class="docs-heading-anchor" href="#Layers">Layers</a><a id="Layers-1"></a><a class="docs-heading-anchor-permalink" href="#Layers" title="Permalink"></a></h2><h3 id="Operator-convolutional-layer"><a class="docs-heading-anchor" href="#Operator-convolutional-layer">Operator convolutional layer</a><a id="Operator-convolutional-layer-1"></a><a class="docs-heading-anchor-permalink" href="#Operator-convolutional-layer" title="Permalink"></a></h3><p class="math-container">\[F(s) = \mathcal{F} \{ v(x) \} \\
F&#39;(s) = g(F(s)) \\
v&#39;(x) = \mathcal{F}^{-1} \{ F&#39;(s) \}\]</p><p>where <span>$v(x)$</span> and <span>$v&#39;(x)$</span> denotes input and output function, <span>$\mathcal{F} \{ \cdot \}$</span>, <span>$\mathcal{F}^{-1} \{ \cdot \}$</span> are the transform and the inverse transform, respectively. Function <span>$g$</span> is a linear transform for lowering spectrum modes.</p><article class="docstring"><header><a class="docstring-binding" id="NeuralOperators.OperatorConv" href="#NeuralOperators.OperatorConv"><code>NeuralOperators.OperatorConv</code></a> ‚Äî <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">OperatorConv(ch, modes, transform;
             init=glorot_uniform, permuted=false, T=ComplexF32)</code></pre><p><strong>Arguments</strong></p><ul><li><code>ch</code>: A <code>Pair</code> of input and output channel size <code>ch_in=&gt;ch_out</code>, e.g. <code>64=&gt;64</code>.</li><li><code>modes</code>: The modes to be preserved. A tuple of length <code>d</code>, where <code>d</code> is the dimension of data.</li><li><code>Transform</code>: The trafo to operate the transformation.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>init</code>: Initial function to initialize parameters.</li><li><code>permuted</code>: Whether the dim is permuted. If <code>permuted=true</code>, the layer accepts data in the order of <code>(ch, x_1, ... , x_d , batch)</code>. Otherwise the order is <code>(x_1, ... , x_d, ch, batch)</code>.</li><li><code>T</code>: Datatype of parameters.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; OperatorConv(2 =&gt; 5, (16,), FourierTransform)
OperatorConv(2 =&gt; 5, (16,), FourierTransform, permuted=false)

julia&gt; OperatorConv(2 =&gt; 5, (16,), FourierTransform, permuted = true)
OperatorConv(2 =&gt; 5, (16,), FourierTransform, permuted=true)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralOperators.jl/blob/3b8e3c5cac08fad771940e82f8ae55247a85785f/src/operator_kernel.jl#L20-L48">source</a></section></article><p>Reference: <a href="../references/#FNO2021">Zongyi Li, Nikola Kovachki, Kamyar Azizzadenesheli, Burigede Liu, Kaushik Bhattacharya, Andrew Stuart, Anima Anandkumar (2021)</a></p><ul><li><ul><li><ul><li></li></ul></li></ul></li></ul><h3 id="Operator-kernel-layer"><a class="docs-heading-anchor" href="#Operator-kernel-layer">Operator kernel layer</a><a id="Operator-kernel-layer-1"></a><a class="docs-heading-anchor-permalink" href="#Operator-kernel-layer" title="Permalink"></a></h3><p class="math-container">\[v_{t+1}(x) = \sigma(W v_t(x) + \mathcal{K} \{ v_t(x) \} )\]</p><p>where <span>$v_t(x)$</span> is the input function for the <span>$t$</span>&#39;th layer and <span>$\mathcal{K} \{ \cdot \}$</span> denotes spectral convolutional layer. Activation function <span>$\sigma$</span> can be an arbitrary non-linear function.</p><article class="docstring"><header><a class="docstring-binding" id="NeuralOperators.OperatorKernel" href="#NeuralOperators.OperatorKernel"><code>NeuralOperators.OperatorKernel</code></a> ‚Äî <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">OperatorKernel(ch, modes, œÉ=identity; permuted=false)</code></pre><p><strong>Arguments</strong></p><ul><li><code>ch</code>: A <code>Pair</code> of input and output channel size for spectral convolution <code>in_ch=&gt;out_ch</code>, e.g. <code>64=&gt;64</code>.</li><li><code>modes</code>: The modes to be preserved for spectral convolution. A tuple of length <code>d</code>, where <code>d</code> is the dimension of data.</li><li><code>œÉ</code>: Activation function.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>permuted</code>: Whether the dim is permuted. If <code>permuted=true</code>, the layer accepts data in the order of <code>(ch, x_1, ... , x_d , batch)</code>, otherwise the order is <code>(x_1, ... , x_d, ch, batch)</code>.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; OperatorKernel(2 =&gt; 5, (16,), FourierTransform)
OperatorKernel(2 =&gt; 5, (16,), FourierTransform, œÉ=identity, permuted=false)

julia&gt; using Flux

julia&gt; OperatorKernel(2 =&gt; 5, (16,), FourierTransform, relu)
OperatorKernel(2 =&gt; 5, (16,), FourierTransform, œÉ=relu, permuted=false)

julia&gt; OperatorKernel(2 =&gt; 5, (16,), FourierTransform, relu, permuted = true)
OperatorKernel(2 =&gt; 5, (16,), FourierTransform, œÉ=relu, permuted=true)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralOperators.jl/blob/3b8e3c5cac08fad771940e82f8ae55247a85785f/src/operator_kernel.jl#L122-L153">source</a></section></article><p>Reference: <a href="../references/#FNO2021">Zongyi Li, Nikola Kovachki, Kamyar Azizzadenesheli, Burigede Liu, Kaushik Bhattacharya, Andrew Stuart, Anima Anandkumar (2021)</a></p><ul><li><ul><li><ul><li></li></ul></li></ul></li></ul><h3 id="Graph-kernel-layer"><a class="docs-heading-anchor" href="#Graph-kernel-layer">Graph kernel layer</a><a id="Graph-kernel-layer-1"></a><a class="docs-heading-anchor-permalink" href="#Graph-kernel-layer" title="Permalink"></a></h3><p class="math-container">\[v_{t+1}(x_i) = \sigma(W v_t(x_i) + \frac{1}{|\mathcal{N}(x_i)|} \sum_{x_j \in \mathcal{N}(x_i)} \kappa \{ v_t(x_i), v_t(x_j) \} )\]</p><p>where <span>$v_t(x_i)$</span> is the input function for <span>$t$</span>-th layer, <span>$x_i$</span> is the node feature for <span>$i$</span>-th node and <span>$\mathcal{N}(x_i)$</span> represents the neighbors for <span>$x_i$</span>. Activation function <span>$\sigma$</span> can be an arbitrary non-linear function.</p><article class="docstring"><header><a class="docstring-binding" id="NeuralOperators.GraphKernel" href="#NeuralOperators.GraphKernel"><code>NeuralOperators.GraphKernel</code></a> ‚Äî <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GraphKernel(Œ∫, ch, œÉ=identity)</code></pre><p>Graph kernel layer.</p><p><strong>Arguments</strong></p><ul><li><code>Œ∫</code>: A neural network layer for approximation, e.g. a <code>Dense</code> layer or a MLP.</li><li><code>ch</code>: Channel size for linear transform, e.g. <code>32</code>.</li><li><code>œÉ</code>: Activation function.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>init</code>: Initial function to initialize parameters.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralOperators.jl/blob/3b8e3c5cac08fad771940e82f8ae55247a85785f/src/graph_kernel.jl#L3-L17">source</a></section></article><p>Reference: <a href="../references/#NO2020">Zongyi Li, Nikola Kovachki, Kamyar Azizzadenesheli, Burigede Liu, Kaushik Bhattacharya, Andrew Stuart, Anima Anandkumar (2020)</a></p><ul><li><ul><li><ul><li></li></ul></li></ul></li></ul><h2 id="Models"><a class="docs-heading-anchor" href="#Models">Models</a><a id="Models-1"></a><a class="docs-heading-anchor-permalink" href="#Models" title="Permalink"></a></h2><h3 id="Fourier-neural-operator"><a class="docs-heading-anchor" href="#Fourier-neural-operator">Fourier neural operator</a><a id="Fourier-neural-operator-1"></a><a class="docs-heading-anchor-permalink" href="#Fourier-neural-operator" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="NeuralOperators.FourierNeuralOperator" href="#NeuralOperators.FourierNeuralOperator"><code>NeuralOperators.FourierNeuralOperator</code></a> ‚Äî <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">FourierNeuralOperator(;
                      ch = (2, 64, 64, 64, 64, 64, 128, 1),
                      modes = (16, ),
                      œÉ = gelu)</code></pre><p>Fourier neural operator is a operator learning model that uses Fourier kernel to perform spectral convolutions. It is a promising way for surrogate methods, and can be regarded as a physics operator.</p><p>The model is comprised of a <code>Dense</code> layer to lift (d + 1)-dimensional vector field to n-dimensional vector field, and an integral kernel operator which consists of four Fourier kernels, and two <code>Dense</code> layers to project data back to the scalar field of interest space.</p><p>The role of each channel size described as follows:</p><pre><code class="nohighlight hljs">[1] input channel number
 ‚Üì Dense
[2] lifted channel number
 ‚Üì OperatorKernel
[3] mapped cahnnel number
 ‚Üì OperatorKernel
[4] mapped cahnnel number
 ‚Üì OperatorKernel
[5] mapped cahnnel number
 ‚Üì OperatorKernel
[6] mapped cahnnel number
 ‚Üì Dense
[7] projected channel number
 ‚Üì Dense
[8] projected channel number</code></pre><p><strong>Keyword Arguments</strong></p><ul><li><code>ch</code>: A <code>Tuple</code> or <code>Vector</code> of the 8 channel size.</li><li><code>modes</code>: The modes to be preserved. A tuple of length <code>d</code>, where <code>d</code> is the dimension of data.</li><li><code>œÉ</code>: Activation function for all layers in the model.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">julia&gt; using NNlib

julia&gt; FourierNeuralOperator(;
                             ch = (2, 64, 64, 64, 64, 64, 128, 1),
                             modes = (16,),
                             œÉ = gelu)
Chain(
  Dense(2 =&gt; 64),                       # 192 parameters
  OperatorKernel(
    Dense(64 =&gt; 64),                    # 4_160 parameters
    OperatorConv(64 =&gt; 64, (16,), FourierTransform, permuted=false),  # 65_536 parameters
    NNlib.gelu,
  ),
  OperatorKernel(
    Dense(64 =&gt; 64),                    # 4_160 parameters
    OperatorConv(64 =&gt; 64, (16,), FourierTransform, permuted=false),  # 65_536 parameters
    NNlib.gelu,
  ),
  OperatorKernel(
    Dense(64 =&gt; 64),                    # 4_160 parameters
    OperatorConv(64 =&gt; 64, (16,), FourierTransform, permuted=false),  # 65_536 parameters
    NNlib.gelu,
  ),
  OperatorKernel(
    Dense(64 =&gt; 64),                    # 4_160 parameters
    OperatorConv(64 =&gt; 64, (16,), FourierTransform, permuted=false),  # 65_536 parameters
    identity,
  ),
  Dense(64 =&gt; 128, gelu),               # 8_320 parameters
  Dense(128 =&gt; 1),                      # 129 parameters
)                   # Total: 18 arrays, 287_425 parameters, 2.098 MiB.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralOperators.jl/blob/3b8e3c5cac08fad771940e82f8ae55247a85785f/src/FNO/FNO.jl#L13-L90">source</a></section></article><p>Reference: <a href="../references/#FNO2021">Zongyi Li, Nikola Kovachki, Kamyar Azizzadenesheli, Burigede Liu, Kaushik Bhattacharya, Andrew Stuart, Anima Anandkumar (2021)</a></p><ul><li><ul><li><ul><li></li></ul></li></ul></li></ul><h3 id="Markov-neural-operator"><a class="docs-heading-anchor" href="#Markov-neural-operator">Markov neural operator</a><a id="Markov-neural-operator-1"></a><a class="docs-heading-anchor-permalink" href="#Markov-neural-operator" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="NeuralOperators.MarkovNeuralOperator" href="#NeuralOperators.MarkovNeuralOperator"><code>NeuralOperators.MarkovNeuralOperator</code></a> ‚Äî <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">MarkovNeuralOperator(;
                     ch = (1, 64, 64, 64, 64, 64, 1),
                     modes = (24, 24),
                     œÉ = gelu)</code></pre><p>Markov neural operator learns a neural operator with Fourier operators. With only one time step information of learning, it can predict the following few steps with low loss by linking the operators into a Markov chain.</p><p>The model is comprised of a <code>Dense</code> layer to lift d-dimensional vector field to n-dimensional vector field, and an integral kernel operator which consists of four Fourier kernels, and a <code>Dense</code> layers to project data back to the scalar field of interest space.</p><p>The role of each channel size described as follows:</p><pre><code class="nohighlight hljs">[1] input channel number
 ‚Üì Dense
[2] lifted channel number
 ‚Üì OperatorKernel
[3] mapped cahnnel number
 ‚Üì OperatorKernel
[4] mapped cahnnel number
 ‚Üì OperatorKernel
[5] mapped cahnnel number
 ‚Üì OperatorKernel
[6] mapped cahnnel number
 ‚Üì Dense
[7] projected channel number</code></pre><p><strong>Keyword Arguments</strong></p><ul><li><code>ch</code>: A <code>Tuple</code> or <code>Vector</code> of the 7 channel size.</li><li><code>modes</code>: The modes to be preserved. A tuple of length <code>d</code>, where <code>d</code> is the dimension of data.</li><li><code>œÉ</code>: Activation function for all layers in the model.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">julia&gt; using NNlib

julia&gt; MarkovNeuralOperator(;
                            ch = (1, 64, 64, 64, 64, 64, 1),
                            modes = (24, 24),
                            œÉ = gelu)
Chain(
  Dense(1 =&gt; 64),                       # 128 parameters
  OperatorKernel(
    Dense(64 =&gt; 64),                    # 4_160 parameters
    OperatorConv(64 =&gt; 64, (24, 24), FourierTransform, permuted=false),  # 2_359_296 parameters
    NNlib.gelu,
  ),
  OperatorKernel(
    Dense(64 =&gt; 64),                    # 4_160 parameters
    OperatorConv(64 =&gt; 64, (24, 24), FourierTransform, permuted=false),  # 2_359_296 parameters
    NNlib.gelu,
  ),
  OperatorKernel(
    Dense(64 =&gt; 64),                    # 4_160 parameters
    OperatorConv(64 =&gt; 64, (24, 24), FourierTransform, permuted=false),  # 2_359_296 parameters
    NNlib.gelu,
  ),
  OperatorKernel(
    Dense(64 =&gt; 64),                    # 4_160 parameters
    OperatorConv(64 =&gt; 64, (24, 24), FourierTransform, permuted=false),  # 2_359_296 parameters
    NNlib.gelu,
  ),
  Dense(64 =&gt; 1),                       # 65 parameters
)                   # Total: 16 arrays, 9_454_017 parameters, 72.066 MiB.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralOperators.jl/blob/3b8e3c5cac08fad771940e82f8ae55247a85785f/src/FNO/FNO.jl#L121-L195">source</a></section></article><p>Reference: <a href="../references/#MNO2021">Zongyi Li, Nikola Kovachki, Kamyar Azizzadenesheli, Burigede Liu, Kaushik Bhattacharya, Andrew Stuart, Anima Anandkumar (2021)</a></p><ul><li><ul><li><ul><li></li></ul></li></ul></li></ul><h3 id="DeepONet"><a class="docs-heading-anchor" href="#DeepONet">DeepONet</a><a id="DeepONet-1"></a><a class="docs-heading-anchor-permalink" href="#DeepONet" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="NeuralOperators.DeepONet" href="#NeuralOperators.DeepONet"><code>NeuralOperators.DeepONet</code></a> ‚Äî <span class="docstring-category">Type</span></header><section><div><p><code>DeepONet(architecture_branch::Tuple, architecture_trunk::Tuple, act_branch = identity, act_trunk = identity; init_branch = Flux.glorot_uniform, init_trunk = Flux.glorot_uniform, bias_branch=true, bias_trunk=true)</code> <code>DeepONet(branch_net::Flux.Chain, trunk_net::Flux.Chain)</code></p><p>Create an (unstacked) DeepONet architecture as proposed by Lu et al. arXiv:1910.03193</p><p>The model works as follows:</p><pre><code class="nohighlight hljs">x --- branch --
               |
                -‚ä†--u-
               |
y --- trunk ---</code></pre><p>Where <code>x</code> represents the input function, discretely evaluated at its respective sensors. So, the input is of shape [m] for one instance or [m x b] for a training set. <code>y</code> are the probing locations for the operator to be trained. It has shape [N x n] for N different variables in the PDE (i.e. spatial and temporal coordinates) with each n distinct evaluation points. <code>u</code> is the solution of the queried instance of the PDE, given by the specific choice of parameters.</p><pre><code class="nohighlight hljs">Both inputs `x` and `y` are multiplied together via dot product Œ£·µ¢ b·µ¢‚±º t·µ¢‚Çñ.

You can set up this architecture in two ways:

1. By Specifying the architecture and all its parameters as given above. This always creates
 `Dense` layers for the branch and trunk net and corresponds to the DeepONet proposed by Lu et al.

2. By passing two architectures in the form of two Chain structs directly. Do this if you want more
flexibility and e.g. use an RNN or CNN instead of simple `Dense` layers.

Strictly speaking, DeepONet does not imply either of the branch or trunk net to be a simple
 DNN. Usually this is the case, which is why it&#39;s treated as the default case here.</code></pre><p><strong>Example</strong></p><p>Consider a transient 1D advection problem ‚àÇ‚Çúu + u ‚ãÖ ‚àáu = 0, with an IC u(x,0) = g(x). We are given several (b = 200) instances of the IC, discretized at 50 points each, and want to query the solution for 100 different locations and times [0;1].</p><p>That makes the branch input of shape [50 x 200] and the trunk input of shape [2 x 100]. So, the input for the branch net is 50 and 100 for the trunk net.</p><p><strong>Usage</strong></p><pre><code class="language-julia hljs">julia&gt; model = DeepONet((32, 64, 72), (24, 64, 72))
DeepONet with
branch net: (Chain(Dense(32, 64), Dense(64, 72)))
Trunk net: (Chain(Dense(24, 64), Dense(64, 72)))

julia&gt; model = DeepONet((32, 64, 72), (24, 64, 72), œÉ, tanh; init_branch = Flux.glorot_normal,
                        bias_trunk = false)
DeepONet with
branch net: (Chain(Dense(32, 64, œÉ), Dense(64, 72, œÉ)))
Trunk net: (Chain(Dense(24, 64, tanh; bias=false), Dense(64, 72, tanh; bias=false)))

julia&gt; branch = Chain(Dense(2, 128), Dense(128, 64), Dense(64, 72))
Chain(
  Dense(2, 128),                        # 384 parameters
  Dense(128, 64),                       # 8_256 parameters
  Dense(64, 72),                        # 4_680 parameters
)                   # Total: 6 arrays, 13_320 parameters, 52.406 KiB.

julia&gt; trunk = Chain(Dense(1, 24), Dense(24, 72))
Chain(
  Dense(1, 24),                         # 48 parameters
  Dense(24, 72),                        # 1_800 parameters
)                   # Total: 4 arrays, 1_848 parameters, 7.469 KiB.

julia&gt; model = DeepONet(branch, trunk)
DeepONet with
branch net: (Chain(Dense(2, 128), Dense(128, 64), Dense(64, 72)))
Trunk net: (Chain(Dense(1, 24), Dense(24, 72)))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralOperators.jl/blob/3b8e3c5cac08fad771940e82f8ae55247a85785f/src/DeepONet/DeepONet.jl#L5-L82">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralOperators.construct_subnet" href="#NeuralOperators.construct_subnet"><code>NeuralOperators.construct_subnet</code></a> ‚Äî <span class="docstring-category">Function</span></header><section><div><p>Construct a Chain of <code>Dense</code> layers from a given tuple of integers.</p><p>Input: A tuple (m,n,o,p) of integer type numbers that each describe the width of the i&#39;th Dense layer to Construct</p><p>Output: A <code>Flux</code> Chain with length of the input tuple and individual width given by the tuple elements</p><p><strong>Example</strong></p><pre><code class="language-julia hljs">julia&gt; model = NeuralOperators.construct_subnet((2, 128, 64, 32, 1))
Chain(
  Dense(2, 128),                        # 384 parameters
  Dense(128, 64),                       # 8_256 parameters
  Dense(64, 32),                        # 2_080 parameters
  Dense(32, 1),                         # 33 parameters
)                   # Total: 8 arrays, 10_753 parameters, 42.504 KiB.

julia&gt; model([2, 1])
1-element Vector{Float32}:
 -0.7630446</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralOperators.jl/blob/3b8e3c5cac08fad771940e82f8ae55247a85785f/src/DeepONet/subnets.jl#L1-L25">source</a></section></article><ul><li><ul><li><ul><li></li></ul></li></ul></li></ul><h3 id="NOMAD"><a class="docs-heading-anchor" href="#NOMAD">NOMAD</a><a id="NOMAD-1"></a><a class="docs-heading-anchor-permalink" href="#NOMAD" title="Permalink"></a></h3><p>Nonlinear manifold decoders for operator learning</p><article class="docstring"><header><a class="docstring-binding" id="NeuralOperators.NOMAD" href="#NeuralOperators.NOMAD"><code>NeuralOperators.NOMAD</code></a> ‚Äî <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">NOMAD(architecture_approximator::Tuple, architecture_decoder::Tuple,
      act_approximator = identity, act_decoder=true;
      init_approximator = Flux.glorot_uniform,
      init_decoder = Flux.glorot_uniform,
      bias_approximator=true, bias_decoder=true)
NOMAD(approximator_net::Flux.Chain, decoder_net::Flux.Chain)</code></pre><p>Create a Nonlinear Manifold Decoders for Operator Learning (NOMAD) as proposed by Lu et al. arXiv:2206.03551</p><p>The decoder is defined as follows:</p><p><span>$\tilde D (Œ≤, y) = f(Œ≤, y)$</span></p><p><strong>Usage</strong></p><pre><code class="language-julia hljs">julia&gt; model = NOMAD((16, 32, 16), (24, 32))
NOMAD with
Approximator net: (Chain(Dense(16 =&gt; 32), Dense(32 =&gt; 16)))
Decoder net: (Chain(Dense(24 =&gt; 32, true)))

julia&gt; model = NeuralOperators.NOMAD((32, 64, 32), (64, 72), œÉ, tanh;
                                     init_approximator = Flux.glorot_normal, bias_decoder = false)
NOMAD with
Approximator net: (Chain(Dense(32 =&gt; 64, œÉ), Dense(64 =&gt; 32, œÉ)))
Decoder net: (Chain(Dense(64 =&gt; 72, tanh; bias=false)))

julia&gt; approximator = Chain(Dense(2, 128), Dense(128, 64))
Chain(
  Dense(2 =&gt; 128),                      # 384 parameters
  Dense(128 =&gt; 64),                     # 8_256 parameters
)                   # Total: 4 arrays, 8_640 parameters, 34.000 KiB.

julia&gt; decoder = Chain(Dense(72, 24), Dense(24, 12))
Chain(
  Dense(72 =&gt; 24),                      # 1_752 parameters
  Dense(24 =&gt; 12),                      # 300 parameters
)                   # Total: 4 arrays, 2_052 parameters, 8.266 KiB.

julia&gt; model = NOMAD(approximator, decoder)
NOMAD with
Approximator net: (Chain(Dense(2 =&gt; 128), Dense(128 =&gt; 64)))
Decoder net: (Chain(Dense(72 =&gt; 24), Dense(24 =&gt; 12)))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralOperators.jl/blob/3b8e3c5cac08fad771940e82f8ae55247a85785f/src/NOMAD/NOMAD.jl#L8-L54">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../introduction/">¬´ Introduction</a><a class="docs-footer-nextpage" href="../references/">References ¬ª</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Tuesday 14 March 2023 17:02">Tuesday 14 March 2023</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
